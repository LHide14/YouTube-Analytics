{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_raw_data.pkl', 'rb') as file:\n",
    "    df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish YoutTube Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id               0\n",
       "channel_id             0\n",
       "published_at           0\n",
       "title                  0\n",
       "description            0\n",
       "tags                   0\n",
       "category_id            0\n",
       "duration               0\n",
       "caption                0\n",
       "licensed_content       0\n",
       "default_language    7444\n",
       "content_rating         0\n",
       "view_count             0\n",
       "like_count            10\n",
       "favourite_count        0\n",
       "comment_count         11\n",
       "channel_name           0\n",
       "subscribers            0\n",
       "total_views            0\n",
       "total_videos           0\n",
       "playlist_id            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>published_at</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>category_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>caption</th>\n",
       "      <th>licensed_content</th>\n",
       "      <th>...</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>total_views</th>\n",
       "      <th>total_videos</th>\n",
       "      <th>playlist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>TSLpULOGkh0</td>\n",
       "      <td>UCteRPiisgIoHtMgqHegpWAQ</td>\n",
       "      <td>2023-02-20T16:25:27Z</td>\n",
       "      <td>How I write SQL FAST with AI (not ChatGPT)? | ...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>PT17S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>24805</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>185000</td>\n",
       "      <td>9376789</td>\n",
       "      <td>116</td>\n",
       "      <td>UUteRPiisgIoHtMgqHegpWAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>poUZXmNQQws</td>\n",
       "      <td>UCteRPiisgIoHtMgqHegpWAQ</td>\n",
       "      <td>2023-02-13T00:26:51Z</td>\n",
       "      <td>Learn Python for Data Analysis #shorts</td>\n",
       "      <td>#python #dataanlytics</td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>PT16S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>10616</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>185000</td>\n",
       "      <td>9376789</td>\n",
       "      <td>116</td>\n",
       "      <td>UUteRPiisgIoHtMgqHegpWAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>sydQQCS5qLM</td>\n",
       "      <td>UCteRPiisgIoHtMgqHegpWAQ</td>\n",
       "      <td>2022-12-16T19:44:53Z</td>\n",
       "      <td>Tech Salaries: I wish this was taught in school</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>PT16S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>18562</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>185000</td>\n",
       "      <td>9376789</td>\n",
       "      <td>116</td>\n",
       "      <td>UUteRPiisgIoHtMgqHegpWAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>FeZ6q064mZc</td>\n",
       "      <td>UCteRPiisgIoHtMgqHegpWAQ</td>\n",
       "      <td>2022-12-04T19:40:55Z</td>\n",
       "      <td>Product Managers: is this true?</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>PT9S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>45952</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>185000</td>\n",
       "      <td>9376789</td>\n",
       "      <td>116</td>\n",
       "      <td>UUteRPiisgIoHtMgqHegpWAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>o3DU3iWXTP0</td>\n",
       "      <td>UCteRPiisgIoHtMgqHegpWAQ</td>\n",
       "      <td>2022-11-12T00:54:57Z</td>\n",
       "      <td>How I would learn data science fast?</td>\n",
       "      <td>Link to book: Practical Statistics For Data Sc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>PT31S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>193258</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>185000</td>\n",
       "      <td>9376789</td>\n",
       "      <td>116</td>\n",
       "      <td>UUteRPiisgIoHtMgqHegpWAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>UGzOFORVn4k</td>\n",
       "      <td>UCteRPiisgIoHtMgqHegpWAQ</td>\n",
       "      <td>2022-10-27T04:41:59Z</td>\n",
       "      <td>The Reality of Big Tech Perks #shorts</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>PT56S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>11501</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>185000</td>\n",
       "      <td>9376789</td>\n",
       "      <td>116</td>\n",
       "      <td>UUteRPiisgIoHtMgqHegpWAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>kDYVQb91vt4</td>\n",
       "      <td>UCteRPiisgIoHtMgqHegpWAQ</td>\n",
       "      <td>2022-10-22T16:57:08Z</td>\n",
       "      <td>Data Analysts vs Data Scientist: True Story? #...</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>28</td>\n",
       "      <td>PT9S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>88825</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>185000</td>\n",
       "      <td>9376789</td>\n",
       "      <td>116</td>\n",
       "      <td>UUteRPiisgIoHtMgqHegpWAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>LAmVx1GIb-s</td>\n",
       "      <td>UCteRPiisgIoHtMgqHegpWAQ</td>\n",
       "      <td>2022-10-21T03:46:15Z</td>\n",
       "      <td>Tech interviews are hard #shorts</td>\n",
       "      <td></td>\n",
       "      <td>[Tech interviews, Coding interviews, FAANG int...</td>\n",
       "      <td>28</td>\n",
       "      <td>PT1M</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>16319</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>Sundas Khalid</td>\n",
       "      <td>185000</td>\n",
       "      <td>9376789</td>\n",
       "      <td>116</td>\n",
       "      <td>UUteRPiisgIoHtMgqHegpWAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>3s_6sV01giw</td>\n",
       "      <td>UCPvDKIsrjA_h3g5yZJwCIHA</td>\n",
       "      <td>2020-08-25T03:48:48Z</td>\n",
       "      <td>Python tutorial | Floating point limitations |...</td>\n",
       "      <td>#pythontutorial #floatlimitations\\nIn this lec...</td>\n",
       "      <td>[python float precision, python float decimal ...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT14M4S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>321</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Tech Classes</td>\n",
       "      <td>30000</td>\n",
       "      <td>1954008</td>\n",
       "      <td>156</td>\n",
       "      <td>UUPvDKIsrjA_h3g5yZJwCIHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>qBTMU9PjG6A</td>\n",
       "      <td>UCzL_0nIe8B4-7ShhVPfJkgw</td>\n",
       "      <td>2023-07-13T07:25:40Z</td>\n",
       "      <td>Build Agents Simply with OpenAI and LangChain ...</td>\n",
       "      <td>In this session, we'll build a chatbot that no...</td>\n",
       "      <td>[openai, langchain, langchain tools, machine l...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT1H5M2S</td>\n",
       "      <td>true</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>956</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Data Science Dojo</td>\n",
       "      <td>101000</td>\n",
       "      <td>5737808</td>\n",
       "      <td>455</td>\n",
       "      <td>UUzL_0nIe8B4-7ShhVPfJkgw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                channel_id          published_at  \\\n",
       "188   TSLpULOGkh0  UCteRPiisgIoHtMgqHegpWAQ  2023-02-20T16:25:27Z   \n",
       "189   poUZXmNQQws  UCteRPiisgIoHtMgqHegpWAQ  2023-02-13T00:26:51Z   \n",
       "196   sydQQCS5qLM  UCteRPiisgIoHtMgqHegpWAQ  2022-12-16T19:44:53Z   \n",
       "199   FeZ6q064mZc  UCteRPiisgIoHtMgqHegpWAQ  2022-12-04T19:40:55Z   \n",
       "202   o3DU3iWXTP0  UCteRPiisgIoHtMgqHegpWAQ  2022-11-12T00:54:57Z   \n",
       "204   UGzOFORVn4k  UCteRPiisgIoHtMgqHegpWAQ  2022-10-27T04:41:59Z   \n",
       "205   kDYVQb91vt4  UCteRPiisgIoHtMgqHegpWAQ  2022-10-22T16:57:08Z   \n",
       "207   LAmVx1GIb-s  UCteRPiisgIoHtMgqHegpWAQ  2022-10-21T03:46:15Z   \n",
       "3792  3s_6sV01giw  UCPvDKIsrjA_h3g5yZJwCIHA  2020-08-25T03:48:48Z   \n",
       "4493  qBTMU9PjG6A  UCzL_0nIe8B4-7ShhVPfJkgw  2023-07-13T07:25:40Z   \n",
       "\n",
       "                                                  title  \\\n",
       "188   How I write SQL FAST with AI (not ChatGPT)? | ...   \n",
       "189              Learn Python for Data Analysis #shorts   \n",
       "196     Tech Salaries: I wish this was taught in school   \n",
       "199                     Product Managers: is this true?   \n",
       "202                How I would learn data science fast?   \n",
       "204               The Reality of Big Tech Perks #shorts   \n",
       "205   Data Analysts vs Data Scientist: True Story? #...   \n",
       "207                    Tech interviews are hard #shorts   \n",
       "3792  Python tutorial | Floating point limitations |...   \n",
       "4493  Build Agents Simply with OpenAI and LangChain ...   \n",
       "\n",
       "                                            description  \\\n",
       "188                                                       \n",
       "189                               #python #dataanlytics   \n",
       "196                                                       \n",
       "199                                                       \n",
       "202   Link to book: Practical Statistics For Data Sc...   \n",
       "204                                                       \n",
       "205                                                       \n",
       "207                                                       \n",
       "3792  #pythontutorial #floatlimitations\\nIn this lec...   \n",
       "4493  In this session, we'll build a chatbot that no...   \n",
       "\n",
       "                                                   tags category_id  duration  \\\n",
       "188                                                  []          28     PT17S   \n",
       "189                                                  []          28     PT16S   \n",
       "196                                                  []          28     PT16S   \n",
       "199                                                  []          28      PT9S   \n",
       "202                                                  []          28     PT31S   \n",
       "204                                                  []          28     PT56S   \n",
       "205                                                  []          28      PT9S   \n",
       "207   [Tech interviews, Coding interviews, FAANG int...          28      PT1M   \n",
       "3792  [python float precision, python float decimal ...          27   PT14M4S   \n",
       "4493  [openai, langchain, langchain tools, machine l...          27  PT1H5M2S   \n",
       "\n",
       "     caption  licensed_content  ... content_rating view_count like_count  \\\n",
       "188    false              True  ...             {}      24805       None   \n",
       "189    false              True  ...             {}      10616       None   \n",
       "196    false              True  ...             {}      18562       None   \n",
       "199    false              True  ...             {}      45952       None   \n",
       "202    false              True  ...             {}     193258       None   \n",
       "204    false              True  ...             {}      11501       None   \n",
       "205    false              True  ...             {}      88825       None   \n",
       "207    false              True  ...             {}      16319       None   \n",
       "3792   false              True  ...             {}        321       None   \n",
       "4493    true             False  ...             {}        956       None   \n",
       "\n",
       "     favourite_count comment_count       channel_name subscribers total_views  \\\n",
       "188                0            24      Sundas Khalid      185000     9376789   \n",
       "189                0            11      Sundas Khalid      185000     9376789   \n",
       "196                0            23      Sundas Khalid      185000     9376789   \n",
       "199                0            31      Sundas Khalid      185000     9376789   \n",
       "202                0           102      Sundas Khalid      185000     9376789   \n",
       "204                0            13      Sundas Khalid      185000     9376789   \n",
       "205                0            63      Sundas Khalid      185000     9376789   \n",
       "207                0            28      Sundas Khalid      185000     9376789   \n",
       "3792               0             2       Tech Classes       30000     1954008   \n",
       "4493               0             2  Data Science Dojo      101000     5737808   \n",
       "\n",
       "     total_videos               playlist_id  \n",
       "188           116  UUteRPiisgIoHtMgqHegpWAQ  \n",
       "189           116  UUteRPiisgIoHtMgqHegpWAQ  \n",
       "196           116  UUteRPiisgIoHtMgqHegpWAQ  \n",
       "199           116  UUteRPiisgIoHtMgqHegpWAQ  \n",
       "202           116  UUteRPiisgIoHtMgqHegpWAQ  \n",
       "204           116  UUteRPiisgIoHtMgqHegpWAQ  \n",
       "205           116  UUteRPiisgIoHtMgqHegpWAQ  \n",
       "207           116  UUteRPiisgIoHtMgqHegpWAQ  \n",
       "3792          156  UUPvDKIsrjA_h3g5yZJwCIHA  \n",
       "4493          455  UUzL_0nIe8B4-7ShhVPfJkgw  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('like_count.isnull()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>published_at</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>category_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>caption</th>\n",
       "      <th>licensed_content</th>\n",
       "      <th>...</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>channel_name</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>total_views</th>\n",
       "      <th>total_videos</th>\n",
       "      <th>playlist_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>sjq1OhMzSSU</td>\n",
       "      <td>UCNU_lfiiWBdtULKOw6X0Dig</td>\n",
       "      <td>2021-01-05T15:22:58Z</td>\n",
       "      <td>Live Virtual Mock Interview For Data Science F...</td>\n",
       "      <td>Nilesh linkedin Id: https://www.linkedin.com/i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>24</td>\n",
       "      <td>PT1H4M31S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>31474</td>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Krish Naik</td>\n",
       "      <td>851000</td>\n",
       "      <td>86329667</td>\n",
       "      <td>1758</td>\n",
       "      <td>UUNU_lfiiWBdtULKOw6X0Dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>lurk94u6_KQ</td>\n",
       "      <td>UCJublDh2UsiIKsAE1553miw</td>\n",
       "      <td>2023-02-03T01:17:52Z</td>\n",
       "      <td>What is Natural Language Processing (NLP)? #sh...</td>\n",
       "      <td>-- -- Natural Language Processing, NLP, Sentim...</td>\n",
       "      <td>[Machine Learning, Data Science, Python, Deep ...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT35S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>1732</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Greg Hogg</td>\n",
       "      <td>61900</td>\n",
       "      <td>4258081</td>\n",
       "      <td>576</td>\n",
       "      <td>UUJublDh2UsiIKsAE1553miw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2769</th>\n",
       "      <td>9oj8r7U0Ekw</td>\n",
       "      <td>UCJublDh2UsiIKsAE1553miw</td>\n",
       "      <td>2023-01-11T21:18:47Z</td>\n",
       "      <td>Is TensorFlow or PyTorch better for deep learn...</td>\n",
       "      <td>-- -- (Links on this page my give me a small c...</td>\n",
       "      <td>[Machine Learning, Data Science, Python, Deep ...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT1M</td>\n",
       "      <td>true</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>41077</td>\n",
       "      <td>1737</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Greg Hogg</td>\n",
       "      <td>61900</td>\n",
       "      <td>4258081</td>\n",
       "      <td>576</td>\n",
       "      <td>UUJublDh2UsiIKsAE1553miw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>zWNWMfQQfJQ</td>\n",
       "      <td>UCJublDh2UsiIKsAE1553miw</td>\n",
       "      <td>2022-05-08T15:20:20Z</td>\n",
       "      <td>Google Deepmind's AI is over 5 years old... bu...</td>\n",
       "      <td>-- -- (Links on this page my give me a small c...</td>\n",
       "      <td>[Machine Learning, Data Science, Python, Deep ...</td>\n",
       "      <td>28</td>\n",
       "      <td>PT15S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>5555</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Greg Hogg</td>\n",
       "      <td>61900</td>\n",
       "      <td>4258081</td>\n",
       "      <td>576</td>\n",
       "      <td>UUJublDh2UsiIKsAE1553miw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>alQKkkyuDjA</td>\n",
       "      <td>UCPvDKIsrjA_h3g5yZJwCIHA</td>\n",
       "      <td>2021-04-29T12:59:25Z</td>\n",
       "      <td>Working with Big Data | Google File System | A...</td>\n",
       "      <td>For notes, you can join gold membership.\\n\\nIn...</td>\n",
       "      <td>[big data analytics, big data, big data analyt...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT8M47S</td>\n",
       "      <td>false</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>25130</td>\n",
       "      <td>364</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Tech Classes</td>\n",
       "      <td>30000</td>\n",
       "      <td>1954008</td>\n",
       "      <td>156</td>\n",
       "      <td>UUPvDKIsrjA_h3g5yZJwCIHA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6425</th>\n",
       "      <td>6uY1KCeLWMY</td>\n",
       "      <td>UC79Gv3mYp6zKiSwYemEik9A</td>\n",
       "      <td>2019-03-07T15:31:01Z</td>\n",
       "      <td>DataCamp for Business</td>\n",
       "      <td>Close the talent gap. Join more than 1,200 com...</td>\n",
       "      <td>[datacamp, business, data science, data visual...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT35S</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>493940</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>DataCamp</td>\n",
       "      <td>155000</td>\n",
       "      <td>22950468</td>\n",
       "      <td>1532</td>\n",
       "      <td>UU79Gv3mYp6zKiSwYemEik9A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7864</th>\n",
       "      <td>TIDaLrcQzs4</td>\n",
       "      <td>UCObs0kLIrDjX2LLSybqNaEA</td>\n",
       "      <td>2021-03-22T13:34:47Z</td>\n",
       "      <td>Analytics Interview Questions | How to Crack A...</td>\n",
       "      <td>➤ Skip Intro:  0:01:18\\n\\nLooking for a career...</td>\n",
       "      <td>[Great Learning, Great Lakes, Data Analytics, ...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT5H25M10S</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>1517</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Great Learning</td>\n",
       "      <td>809000</td>\n",
       "      <td>63094287</td>\n",
       "      <td>1857</td>\n",
       "      <td>UUObs0kLIrDjX2LLSybqNaEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8007</th>\n",
       "      <td>ZMGCzGhIwf0</td>\n",
       "      <td>UCObs0kLIrDjX2LLSybqNaEA</td>\n",
       "      <td>2021-01-19T07:33:17Z</td>\n",
       "      <td>Introduction to SQL | SQL Tutorial for Beginne...</td>\n",
       "      <td>🔥1000+ Free Courses With Free Certificates: ht...</td>\n",
       "      <td>[Great Learning, Great Lakes, Data Analytics, ...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT59M26S</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>9559</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Great Learning</td>\n",
       "      <td>809000</td>\n",
       "      <td>63094287</td>\n",
       "      <td>1857</td>\n",
       "      <td>UUObs0kLIrDjX2LLSybqNaEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>zchbiQSAL3o</td>\n",
       "      <td>UCObs0kLIrDjX2LLSybqNaEA</td>\n",
       "      <td>2021-01-16T12:00:12Z</td>\n",
       "      <td>Natural Language Processing Interview Question...</td>\n",
       "      <td>🔥1000+ Free Courses With Free Certificates: ht...</td>\n",
       "      <td>[NLP Interview Questions, NLP Interview, Natur...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT1H26M41S</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>11602</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Great Learning</td>\n",
       "      <td>809000</td>\n",
       "      <td>63094287</td>\n",
       "      <td>1857</td>\n",
       "      <td>UUObs0kLIrDjX2LLSybqNaEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8222</th>\n",
       "      <td>ukktPIhvXJg</td>\n",
       "      <td>UCObs0kLIrDjX2LLSybqNaEA</td>\n",
       "      <td>2020-10-06T11:33:36Z</td>\n",
       "      <td>Getting started with Machine Learning | Python...</td>\n",
       "      <td>🔥1000+ Free Courses With Free Certificates: ht...</td>\n",
       "      <td>[machine learning with python, python for mach...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT1H</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>3896</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Great Learning</td>\n",
       "      <td>809000</td>\n",
       "      <td>63094287</td>\n",
       "      <td>1857</td>\n",
       "      <td>UUObs0kLIrDjX2LLSybqNaEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8610</th>\n",
       "      <td>Bqw99eML13I</td>\n",
       "      <td>UCObs0kLIrDjX2LLSybqNaEA</td>\n",
       "      <td>2019-10-23T08:48:08Z</td>\n",
       "      <td>This Diwali Give Your Career A #NewBeginning |...</td>\n",
       "      <td>We all had childhood dreams. Many of us likely...</td>\n",
       "      <td>[Great Learning, Great Lakes, Data Analytics, ...</td>\n",
       "      <td>27</td>\n",
       "      <td>PT1M1S</td>\n",
       "      <td>false</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>{}</td>\n",
       "      <td>586</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>Great Learning</td>\n",
       "      <td>809000</td>\n",
       "      <td>63094287</td>\n",
       "      <td>1857</td>\n",
       "      <td>UUObs0kLIrDjX2LLSybqNaEA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                channel_id          published_at  \\\n",
       "1473  sjq1OhMzSSU  UCNU_lfiiWBdtULKOw6X0Dig  2021-01-05T15:22:58Z   \n",
       "2756  lurk94u6_KQ  UCJublDh2UsiIKsAE1553miw  2023-02-03T01:17:52Z   \n",
       "2769  9oj8r7U0Ekw  UCJublDh2UsiIKsAE1553miw  2023-01-11T21:18:47Z   \n",
       "2879  zWNWMfQQfJQ  UCJublDh2UsiIKsAE1553miw  2022-05-08T15:20:20Z   \n",
       "3745  alQKkkyuDjA  UCPvDKIsrjA_h3g5yZJwCIHA  2021-04-29T12:59:25Z   \n",
       "6425  6uY1KCeLWMY  UC79Gv3mYp6zKiSwYemEik9A  2019-03-07T15:31:01Z   \n",
       "7864  TIDaLrcQzs4  UCObs0kLIrDjX2LLSybqNaEA  2021-03-22T13:34:47Z   \n",
       "8007  ZMGCzGhIwf0  UCObs0kLIrDjX2LLSybqNaEA  2021-01-19T07:33:17Z   \n",
       "8011  zchbiQSAL3o  UCObs0kLIrDjX2LLSybqNaEA  2021-01-16T12:00:12Z   \n",
       "8222  ukktPIhvXJg  UCObs0kLIrDjX2LLSybqNaEA  2020-10-06T11:33:36Z   \n",
       "8610  Bqw99eML13I  UCObs0kLIrDjX2LLSybqNaEA  2019-10-23T08:48:08Z   \n",
       "\n",
       "                                                  title  \\\n",
       "1473  Live Virtual Mock Interview For Data Science F...   \n",
       "2756  What is Natural Language Processing (NLP)? #sh...   \n",
       "2769  Is TensorFlow or PyTorch better for deep learn...   \n",
       "2879  Google Deepmind's AI is over 5 years old... bu...   \n",
       "3745  Working with Big Data | Google File System | A...   \n",
       "6425                              DataCamp for Business   \n",
       "7864  Analytics Interview Questions | How to Crack A...   \n",
       "8007  Introduction to SQL | SQL Tutorial for Beginne...   \n",
       "8011  Natural Language Processing Interview Question...   \n",
       "8222  Getting started with Machine Learning | Python...   \n",
       "8610  This Diwali Give Your Career A #NewBeginning |...   \n",
       "\n",
       "                                            description  \\\n",
       "1473  Nilesh linkedin Id: https://www.linkedin.com/i...   \n",
       "2756  -- -- Natural Language Processing, NLP, Sentim...   \n",
       "2769  -- -- (Links on this page my give me a small c...   \n",
       "2879  -- -- (Links on this page my give me a small c...   \n",
       "3745  For notes, you can join gold membership.\\n\\nIn...   \n",
       "6425  Close the talent gap. Join more than 1,200 com...   \n",
       "7864  ➤ Skip Intro:  0:01:18\\n\\nLooking for a career...   \n",
       "8007  🔥1000+ Free Courses With Free Certificates: ht...   \n",
       "8011  🔥1000+ Free Courses With Free Certificates: ht...   \n",
       "8222  🔥1000+ Free Courses With Free Certificates: ht...   \n",
       "8610  We all had childhood dreams. Many of us likely...   \n",
       "\n",
       "                                                   tags category_id  \\\n",
       "1473                                                 []          24   \n",
       "2756  [Machine Learning, Data Science, Python, Deep ...          27   \n",
       "2769  [Machine Learning, Data Science, Python, Deep ...          27   \n",
       "2879  [Machine Learning, Data Science, Python, Deep ...          28   \n",
       "3745  [big data analytics, big data, big data analyt...          27   \n",
       "6425  [datacamp, business, data science, data visual...          27   \n",
       "7864  [Great Learning, Great Lakes, Data Analytics, ...          27   \n",
       "8007  [Great Learning, Great Lakes, Data Analytics, ...          27   \n",
       "8011  [NLP Interview Questions, NLP Interview, Natur...          27   \n",
       "8222  [machine learning with python, python for mach...          27   \n",
       "8610  [Great Learning, Great Lakes, Data Analytics, ...          27   \n",
       "\n",
       "        duration caption  licensed_content  ... content_rating view_count  \\\n",
       "1473   PT1H4M31S   false              True  ...             {}      31474   \n",
       "2756       PT35S   false              True  ...             {}       1732   \n",
       "2769        PT1M    true              True  ...             {}      41077   \n",
       "2879       PT15S   false              True  ...             {}       5555   \n",
       "3745     PT8M47S   false              True  ...             {}      25130   \n",
       "6425       PT35S   false             False  ...             {}     493940   \n",
       "7864  PT5H25M10S   false             False  ...             {}       1517   \n",
       "8007    PT59M26S   false             False  ...             {}       9559   \n",
       "8011  PT1H26M41S   false             False  ...             {}      11602   \n",
       "8222        PT1H   false             False  ...             {}       3896   \n",
       "8610      PT1M1S   false             False  ...             {}        586   \n",
       "\n",
       "     like_count favourite_count comment_count    channel_name subscribers  \\\n",
       "1473        822               0          None      Krish Naik      851000   \n",
       "2756        110               0          None       Greg Hogg       61900   \n",
       "2769       1737               0          None       Greg Hogg       61900   \n",
       "2879        135               0          None       Greg Hogg       61900   \n",
       "3745        364               0          None    Tech Classes       30000   \n",
       "6425         46               0          None        DataCamp      155000   \n",
       "7864         72               0          None  Great Learning      809000   \n",
       "8007        284               0          None  Great Learning      809000   \n",
       "8011        230               0          None  Great Learning      809000   \n",
       "8222        144               0          None  Great Learning      809000   \n",
       "8610          9               0          None  Great Learning      809000   \n",
       "\n",
       "     total_views total_videos               playlist_id  \n",
       "1473    86329667         1758  UUNU_lfiiWBdtULKOw6X0Dig  \n",
       "2756     4258081          576  UUJublDh2UsiIKsAE1553miw  \n",
       "2769     4258081          576  UUJublDh2UsiIKsAE1553miw  \n",
       "2879     4258081          576  UUJublDh2UsiIKsAE1553miw  \n",
       "3745     1954008          156  UUPvDKIsrjA_h3g5yZJwCIHA  \n",
       "6425    22950468         1532  UU79Gv3mYp6zKiSwYemEik9A  \n",
       "7864    63094287         1857  UUObs0kLIrDjX2LLSybqNaEA  \n",
       "8007    63094287         1857  UUObs0kLIrDjX2LLSybqNaEA  \n",
       "8011    63094287         1857  UUObs0kLIrDjX2LLSybqNaEA  \n",
       "8222    63094287         1857  UUObs0kLIrDjX2LLSybqNaEA  \n",
       "8610    63094287         1857  UUObs0kLIrDjX2LLSybqNaEA  \n",
       "\n",
       "[11 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('comment_count.isnull()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en       1209\n",
       "en-US     526\n",
       "en-IN     142\n",
       "en-CA       1\n",
       "Name: default_language, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.default_language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Null Findings*:\n",
    "\n",
    "* default language - has not been filled in by some creators, will be dropped as not enough have valid values, only different types of english no other languages\n",
    "* like count - ten nulls that are actually just 0, will be filled with 0\n",
    "* comment count - eleven nulls that are actually just 0, will be filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.like_count.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.comment_count.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='default_language', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id            0\n",
       "channel_id          0\n",
       "published_at        0\n",
       "title               0\n",
       "description         0\n",
       "tags                0\n",
       "category_id         0\n",
       "duration            0\n",
       "caption             0\n",
       "licensed_content    0\n",
       "content_rating      0\n",
       "view_count          0\n",
       "like_count          0\n",
       "favourite_count     0\n",
       "comment_count       0\n",
       "channel_name        0\n",
       "subscribers         0\n",
       "total_views         0\n",
       "total_videos        0\n",
       "playlist_id         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping favourite count as it is now defunct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='favourite_count', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['video_id', 'channel_id', 'published_at', 'title', 'description',\n",
       "       'tags', 'category_id', 'duration', 'caption', 'licensed_content',\n",
       "       'content_rating', 'view_count', 'like_count', 'comment_count',\n",
       "       'channel_name', 'subscribers', 'total_views', 'total_videos',\n",
       "       'playlist_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id            object\n",
       "channel_id          object\n",
       "published_at        object\n",
       "title               object\n",
       "description         object\n",
       "tags                object\n",
       "category_id         object\n",
       "duration            object\n",
       "caption             object\n",
       "licensed_content      bool\n",
       "content_rating      object\n",
       "view_count          object\n",
       "like_count          object\n",
       "comment_count       object\n",
       "channel_name        object\n",
       "subscribers         object\n",
       "total_views         object\n",
       "total_videos        object\n",
       "playlist_id         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What should our data types be?\n",
    "\n",
    "* **'video_id'** - object to str as more efficient\n",
    "* **'channel_id'** - object to str as more efficient\n",
    "* **'published_at'** - object to datetime64\n",
    "* **'title'** - object to str as more efficient and better for NLP\n",
    "* **'description'** - object to str as more efficient and better for NLP\n",
    "* **'tags'** - no change needed\n",
    "* **'category_id'** - to be a string after API query\n",
    "* **'duration'** - object to timedelta\n",
    "* **'caption'** - object to bool\n",
    "* **'licensed_content'** - object to bool\n",
    "* **'content_rating'** - empty string dictionary, to be dropped\n",
    "* **'view_count'** - object to int for calculations\n",
    "* **'like_count'** - object to int for calculations\n",
    "* **'comment_count'** - object to int for calculations\n",
    "* **'channel_name'** - object to str as more efficient\n",
    "* **'subscribers'** - object to int for calculations\n",
    "* **'total_views'** - object to int for calculations\n",
    "* **'total_videos'** - object to int for calculations\n",
    "* **'playlist_id'** - object to str as more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object to Str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_str = ['video_id', 'channel_id', 'title', 'description', 'channel_name', 'playlist_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_str:\n",
    "    df[column] = df[column].astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_int = ['view_count', 'like_count', 'comment_count', 'subscribers', 'total_views', 'total_videos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_int:\n",
    "    df[column] = df[column].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YouTube Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(youtube, wanted_categories):\n",
    "\n",
    "    all_data = []\n",
    "    \n",
    "    request = youtube.videoCategories().list(part='snippet', id=','.join(wanted_categories))\n",
    "    \n",
    "    response = request.execute()\n",
    "    \n",
    "    for i in range(len(response['items'])):\n",
    "        data = dict(category_id = response['items'][i]['id'],\n",
    "                category= response['items'][i]['snippet']['title'])\n",
    "        all_data.append(data)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_id'] = df['category_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['27' '24' '28' '22' '2' '1' '10' '26' '20' '19' '17' '23']\n"
     ]
    }
   ],
   "source": [
    "category_ids = df['category_id'].unique()\n",
    "print(category_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'category_id': '1', 'category': 'Film & Animation'}, {'category_id': '2', 'category': 'Autos & Vehicles'}, {'category_id': '10', 'category': 'Music'}, {'category_id': '17', 'category': 'Sports'}, {'category_id': '19', 'category': 'Travel & Events'}, {'category_id': '20', 'category': 'Gaming'}, {'category_id': '22', 'category': 'People & Blogs'}, {'category_id': '23', 'category': 'Comedy'}, {'category_id': '24', 'category': 'Entertainment'}, {'category_id': '26', 'category': 'Howto & Style'}, {'category_id': '27', 'category': 'Education'}, {'category_id': '28', 'category': 'Science & Technology'}]\n"
     ]
    }
   ],
   "source": [
    "category_dict = get_categories(youtube, category_ids)\n",
    "print(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Film &amp; Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Autos &amp; Vehicles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>Sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>Travel &amp; Events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>Gaming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>People &amp; Blogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28</td>\n",
       "      <td>Science &amp; Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id              category\n",
       "0            1      Film & Animation\n",
       "1            2      Autos & Vehicles\n",
       "2           10                 Music\n",
       "3           17                Sports\n",
       "4           19       Travel & Events\n",
       "5           20                Gaming\n",
       "6           22        People & Blogs\n",
       "7           23                Comedy\n",
       "8           24         Entertainment\n",
       "9           26         Howto & Style\n",
       "10          27             Education\n",
       "11          28  Science & Technology"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_df = pd.DataFrame(category_dict)\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, category_df, on='category_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stripping of the 'PT' from begining of duration values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration'] = df['duration'].str.replace('PT', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to reformat the duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_duration(time_string):\n",
    "\n",
    "    # store hours, minutes, seconds as integers\n",
    "    H = 0\n",
    "    M = 0\n",
    "    S = 0\n",
    "\n",
    "    # check if vid time contains hours, minutes and/or seconds\n",
    "    if 'H' in time_string:\n",
    "        H += int(time_string.split('H')[0])\n",
    "    if 'M' in time_string:\n",
    "        M += int(time_string.split('M')[0].split('H')[-1])\n",
    "    if 'S' in time_string:\n",
    "        S += int(time_string.split('S')[0].split('M')[-1].split('H')[-1])\n",
    "    \n",
    "    formatted_time = timedelta(hours=H, minutes=M, seconds=S)\n",
    "\n",
    "    return formatted_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['duration_formatted'] = df['duration'].apply(format_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Published Data Format to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['published_at_formatted'] = df['published_at'].str.replace('Z','')\n",
    "\n",
    "# format published date column to datetime\n",
    "df['published_at_formatted'] = df.published_at_formatted.apply(datetime.datetime.fromisoformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object to bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_bool = ['caption', 'licensed_content']\n",
    "\n",
    "for column in columns_to_bool:\n",
    "    df[column] = df[column].astype('bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Tags column creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column of unique tag count for each video\n",
    "df['no_of_tags'] = df['tags'].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_length'] = df['title'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_length'] = df['description'].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Column Dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id                           string\n",
       "channel_id                         string\n",
       "published_at                       object\n",
       "title                              string\n",
       "description                        string\n",
       "tags                               object\n",
       "category_id                        object\n",
       "duration                           object\n",
       "caption                              bool\n",
       "licensed_content                     bool\n",
       "content_rating                     object\n",
       "view_count                          int64\n",
       "like_count                          int64\n",
       "comment_count                       int64\n",
       "channel_name                       string\n",
       "subscribers                         int64\n",
       "total_views                         int64\n",
       "total_videos                        int64\n",
       "playlist_id                        string\n",
       "category                           object\n",
       "duration_formatted        timedelta64[ns]\n",
       "published_at_formatted     datetime64[ns]\n",
       "no_of_tags                          int64\n",
       "title_length                        int64\n",
       "description_length                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['published_at', 'category_id', 'duration', 'content_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Clean Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_clean_data.pkl', 'wb') as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>tags</th>\n",
       "      <th>caption</th>\n",
       "      <th>licensed_content</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>...</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>total_views</th>\n",
       "      <th>total_videos</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>category</th>\n",
       "      <th>duration_formatted</th>\n",
       "      <th>published_at_formatted</th>\n",
       "      <th>no_of_tags</th>\n",
       "      <th>title_length</th>\n",
       "      <th>description_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3fqTNzXY5tg</td>\n",
       "      <td>UCvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Using Code and GPT-3 to Learn Faster</td>\n",
       "      <td>Thanks to ProjectPro.io for their support: htt...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6871</td>\n",
       "      <td>184</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>140000</td>\n",
       "      <td>6562136</td>\n",
       "      <td>152</td>\n",
       "      <td>UUvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Education</td>\n",
       "      <td>0 days 00:18:06</td>\n",
       "      <td>2023-02-19 14:00:02</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bgVu5WVR9SE</td>\n",
       "      <td>UCvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Data Analyst MENTORSHIP -  Q&amp;A (while I drink ...</td>\n",
       "      <td>⬇️⬇️⬇️Check here prior to asking your question...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3723</td>\n",
       "      <td>184</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>140000</td>\n",
       "      <td>6562136</td>\n",
       "      <td>152</td>\n",
       "      <td>UUvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Education</td>\n",
       "      <td>0 days 00:29:22</td>\n",
       "      <td>2022-11-04 03:32:38</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4we3smhjAB8</td>\n",
       "      <td>UCvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>How Data Science ACTUALLY Works</td>\n",
       "      <td>Check out Deepnote for the easiest way to prac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>85152</td>\n",
       "      <td>2647</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>140000</td>\n",
       "      <td>6562136</td>\n",
       "      <td>152</td>\n",
       "      <td>UUvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Education</td>\n",
       "      <td>0 days 00:26:50</td>\n",
       "      <td>2022-11-01 16:30:09</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lpF5SSgczeE</td>\n",
       "      <td>UCvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Does Instagram think you live in an influentia...</td>\n",
       "      <td>Request this and many other datasets @: https:...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4470</td>\n",
       "      <td>158</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>140000</td>\n",
       "      <td>6562136</td>\n",
       "      <td>152</td>\n",
       "      <td>UUvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Education</td>\n",
       "      <td>0 days 01:24:08</td>\n",
       "      <td>2022-10-25 14:00:07</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>1059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cRVM-LTe3fI</td>\n",
       "      <td>UCvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Data Analyst MENTORSHIP -  Q&amp;A (while I drink ...</td>\n",
       "      <td>⬇️⬇️⬇️Check here prior to asking your question...</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3078</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>140000</td>\n",
       "      <td>6562136</td>\n",
       "      <td>152</td>\n",
       "      <td>UUvZnwzmc3m1Eush-Or8Z6DA</td>\n",
       "      <td>Education</td>\n",
       "      <td>0 days 00:26:55</td>\n",
       "      <td>2022-10-07 03:36:26</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                channel_id  \\\n",
       "0  3fqTNzXY5tg  UCvZnwzmc3m1Eush-Or8Z6DA   \n",
       "1  bgVu5WVR9SE  UCvZnwzmc3m1Eush-Or8Z6DA   \n",
       "2  4we3smhjAB8  UCvZnwzmc3m1Eush-Or8Z6DA   \n",
       "3  lpF5SSgczeE  UCvZnwzmc3m1Eush-Or8Z6DA   \n",
       "4  cRVM-LTe3fI  UCvZnwzmc3m1Eush-Or8Z6DA   \n",
       "\n",
       "                                               title  \\\n",
       "0               Using Code and GPT-3 to Learn Faster   \n",
       "1  Data Analyst MENTORSHIP -  Q&A (while I drink ...   \n",
       "2                    How Data Science ACTUALLY Works   \n",
       "3  Does Instagram think you live in an influentia...   \n",
       "4  Data Analyst MENTORSHIP -  Q&A (while I drink ...   \n",
       "\n",
       "                                         description tags  caption  \\\n",
       "0  Thanks to ProjectPro.io for their support: htt...   []     True   \n",
       "1  ⬇️⬇️⬇️Check here prior to asking your question...   []     True   \n",
       "2  Check out Deepnote for the easiest way to prac...   []     True   \n",
       "3  Request this and many other datasets @: https:...   []     True   \n",
       "4  ⬇️⬇️⬇️Check here prior to asking your question...   []     True   \n",
       "\n",
       "   licensed_content  view_count  like_count  comment_count  ... subscribers  \\\n",
       "0              True        6871         184             23  ...      140000   \n",
       "1              True        3723         184              9  ...      140000   \n",
       "2              True       85152        2647            136  ...      140000   \n",
       "3              True        4470         158             12  ...      140000   \n",
       "4              True        3078         104              4  ...      140000   \n",
       "\n",
       "   total_views  total_videos               playlist_id   category  \\\n",
       "0      6562136           152  UUvZnwzmc3m1Eush-Or8Z6DA  Education   \n",
       "1      6562136           152  UUvZnwzmc3m1Eush-Or8Z6DA  Education   \n",
       "2      6562136           152  UUvZnwzmc3m1Eush-Or8Z6DA  Education   \n",
       "3      6562136           152  UUvZnwzmc3m1Eush-Or8Z6DA  Education   \n",
       "4      6562136           152  UUvZnwzmc3m1Eush-Or8Z6DA  Education   \n",
       "\n",
       "  duration_formatted published_at_formatted no_of_tags  title_length  \\\n",
       "0    0 days 00:18:06    2023-02-19 14:00:02          0            36   \n",
       "1    0 days 00:29:22    2022-11-04 03:32:38          0            53   \n",
       "2    0 days 00:26:50    2022-11-01 16:30:09          0            31   \n",
       "3    0 days 01:24:08    2022-10-25 14:00:07          0            81   \n",
       "4    0 days 00:26:55    2022-10-07 03:36:26          0            53   \n",
       "\n",
       "   description_length  \n",
       "0                 795  \n",
       "1                1475  \n",
       "2                1205  \n",
       "3                1059  \n",
       "4                1475  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
